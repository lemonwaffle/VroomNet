{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab AI for S.E.A.: Computer Vision Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Grab AI for S.E.A. Computer Vision Challenge](https://static.wixstatic.com/media/397bed_b98b08c6fc6848d1b280cc16d5462818~mv2.png/v1/fill/w_305,h_305,al_c,q_80,usm_0.66_1.00_0.01/Grab%20EDM_Computer%20Vision.webp)  \n",
    "\n",
    "*Taken from: [Grab AI for S.E.A.](https://www.aiforsea.com/computer-vision)*\n",
    "\n",
    "**Problem Statement**\n",
    "> Given a dataset of distinct car images, can you automatically recognize the car model and make?\n",
    "\n",
    "**Introduction**  \n",
    "This challenge is a Fine-Grained Image Classification task; where a model has to be built to differentiate between hard-to-distinguish object classes, for e.g. the various makes or models of vehicles.\n",
    "\n",
    "Such an endeavor can prove to be challenging as objects that belong to different classes may only contain subtle differences. In the context of this challenge, my trained models have the most difficulty in differentiating between cars of the same make and model, but produced in different years - a task that is probably only right up the alley of car enthusiasts.\n",
    "\n",
    "**Dataset**  \n",
    "The dataset for this challenge is the [Stanford Cars Dataset](https://ai.stanford.edu/~jkrause/cars/car_dataset.html). It contains a total of 16,185 images, split into a training set of 8,144 images and a testing set of 8,041 images. The images are labeled at the level of Make, Model, Year, making up a total of 196 classes, and additionally contains bounding box labels that localizes the car in each image.\n",
    "\n",
    "**Evaluation**  \n",
    "The model should output a confidence score for every classification, and will be evaluated by accuracy, precision, and recall.\n",
    "\n",
    "**Table of Contents**\n",
    "1. Summary of Approach\n",
    "2. Lel  \n",
    "    2.1 Jesus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my solution, I did not attempt to reinvent the wheel; rather, I took this challenge as a learning opportunity for me to, \n",
    "1. Familiarize myself with the popular and proven approaches for image classification, \n",
    "2. Successfully implement an end-to-end machine learning pipeline, and to\n",
    "3. Document my results and process comprehensively.\n",
    "\n",
    "I started off with a simple tried-and-tested ResNet50 model as a simple baseline, supplemented it with various approaches to get sense of what works, then finally proceeded to test out larger and more complicated architectures.\n",
    "\n",
    "As follows is a **TD;LR** of my final solution:\n",
    "\n",
    "**Validation Scheme**\n",
    "- Simple 20% hold-out validation set.\n",
    "- Split using stratified sampling to preserve class proportions. \n",
    "\n",
    "**Data Preprocessing**\n",
    "- Images resized to 224 x 244.\n",
    "- Normalized using ImageNet statistics to feed into a pretrained model.\n",
    "- Train-time traditional data augmentation + mixup data augmentation.\n",
    "\n",
    "**Model Architectures**\n",
    "- ResNet50, ResNet101\n",
    "- SEResNeXt101\n",
    "\n",
    "**Optimization**\n",
    "- Learning rate finder\n",
    "- One-cycle policy\n",
    "- What optimizer?\n",
    "\n",
    "**Training Regime**\n",
    "- Stage-1: Transfer learning, only train classifier head.\n",
    "- Stage-2: Fine-tune entire model, using discriminative layer training.\n",
    "- Stage-3: Fine-tune model from previous stage, by using images of increased size.\n",
    "\n",
    "**Post-processing**\n",
    "- Test-time augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Did not manage to ascertain the reproducibility of my training performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
